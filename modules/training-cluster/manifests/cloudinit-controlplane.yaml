#cloud-config
%{ if length(extra_ssh_keys) > 0 }
ssh_authorized_keys:
%{ for ssh_key in extra_ssh_keys }
- ${ssh_key}
%{ endfor }
%{ endif }
packages:
- git
- jq
- curl
- unattended-upgrades
- open-iscsi
- nfs-common
package_update: true
package_upgrade: true
runcmd:
- echo "*               soft    nofile          1000000" >> /etc/security/limits.conf
- echo "*               hard    nofile          1000000" >> /etc/security/limits.conf
- echo 'fs.file-max = 1000000' >> /etc/sysctl.conf
- echo 'fs.inotify.max_user_instances=8192' >> /etc/sysctl.conf
- echo 'fs.inotify.max_user_watches=524288' >> /etc/sysctl.conf
- sysctl -p
- /opt/rke2/run_rke2.sh
- rm /opt/rke2/run_rke2.sh
write_files:
- path: /var/lib/rancher/rke2/server/manifests/hcloud-secret.yaml
  permission: "0600"
  owner: root:root
  content: |
    ---
    apiVersion: v1
    data:
      token: ${base64encode(api_token)}
      network: ${base64encode(network)}
      hcloudApiToken: ${base64encode(api_token)}
    kind: Secret
    metadata:
      name: hcloud
      namespace: kube-system
    type: Opaque
- path: /var/lib/rancher/rke2/server/manifests/hcloud-cloud-controller-manager.yaml
  permission: "0600"
  owner: root:root
  content: |    cluster-cidr: ${k8s-cluster-cidr}
    ---
    apiVersion: helm.cattle.io/v1
    kind: HelmChart
    metadata:
      name: hccm
      namespace: kube-system
    spec:
      chart: hcloud-cloud-controller-manager
      targetNamespace: kube-system
      repo: https://charts.hetzner.cloud
      bootstrap: true
      version: v1.20.0
      valuesContent: |-
        env:
          HCLOUD_LOAD_BALANCERS_LOCATION: 
            value: ${location}
          HCLOUD_LOAD_BALANCERS_USE_PRIVATE_IP:
            value: "true"
          HCLOUD_TOKEN:
            valueFrom:
              secretKeyRef:
                name: hcloud
                key: token
          NODE_NAME:
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
- path: /var/lib/rancher/rke2/server/manifests/rke2-cilium-config.yaml
  permission: "0600"
  owner: root:root
  content: |
    ---
    apiVersion: helm.cattle.io/v1
    kind: HelmChartConfig
    metadata:
      name: rke2-cilium
      namespace: kube-system
    spec:
      valuesContent: |-
        kubeProxyReplacement: true
        k8sServiceHost: ${lb_address}
        k8sServicePort: 6443
        ipam:
          mode: kubernetes
        socketLB:
          hostNamespaceOnly: true
        hubble:
          enabled: true
          metrics:
            serviceMonitor:
              enabled: false
            enabled:
            - dns:query;ignoreAAAA
            - drop
            - tcp
            - flow
            - icmp
            - http
          relay:
            enabled: true
          ui:
            enabled: true
        operator:
          prometheus:
            enabled: true
            serviceMonitor:
              enabled: false
        prometheus:
          enabled: true
          serviceMonitor:
            enabled: false
- path: /var/lib/rancher/rke2/server/manifests/rke2-metrics-server-config.yaml
  permission: "0600"
  owner: root:root
  content: |
    ---
    apiVersion: helm.cattle.io/v1
    kind: HelmChartConfig
    metadata:
      name: rke2-metrics-server
      namespace: kube-system
    spec:
      valuesContent: |-
        nodeSelector:
          node-role.kubernetes.io/control-plane: "true"
        tolerations:
        - key: "node-role.kubernetes.io/control-plane"
          operator: "Exists"
          effect: "NoSchedule"
- path: /var/lib/rancher/rke2/server/manifests/rke2-coredns-config.yaml
  permission: "0600"
  owner: root:root
  content: |
    ---
    apiVersion: helm.cattle.io/v1
    kind: HelmChartConfig
    metadata:
      name: rke2-coredns
      namespace: kube-system
    spec:
      valuesContent: |-
        nodeSelector:
          node-role.kubernetes.io/control-plane: "true"
- path: /etc/rancher/rke2/config.yaml
  permissions: "0600"
  owner: root:root
  content: |
    %{ if controlplane_index != 0 || !first_install}
    server: https://${lb_address}:9345
    %{ endif }
    cni: cilium
    disable:
    - rke2-ingress-nginx
    disable-cloud-controller: true
    disable-kube-proxy: true
    cloud-provider-name: external
    tls-san:
      - ${lb_address}
      - ${lb_external_v4}
      - ${lb_external_v6}
     %{ for k8s_api_hostname in k8s_api_hostnames }
      - ${k8s_api_hostname}
     %{ endfor }
    token: ${rke2_cluster_secret}
    node-taint:
      - "node-role.kubernetes.io/control-plane=true:NoSchedule"
- path: /opt/rke2/run_rke2.sh
  permissions: "0755"
  owner: root:root
  content: |
    #!/bin/bash
    %{ if controlplane_index != 0 }
    function num_healthy {
      jq -r '[.load_balancer.targets | .[] | select(.label_selector.selector == "cluster=${clustername},controlplane=true") | .targets | .[] | select(.health_status | all(.status == "healthy"))] | length'
    }
    function get_lb {
      LB="$(echo ${lb_id} | cut -d \- -f 1)"
      curl -sSL -H "Authorization: Bearer ${api_token}" "https://api.hetzner.cloud/v1/load_balancers/$LB"
    }
    while true; do
      res="$(get_lb | num_healthy)"
      if [ "$?" == 0 ] && [ "$res" -ge ${controlplane_index} ]; then
        break
      fi
      echo "not enought controlplanes ready to join next ($res / ${controlplane_index})"
      sleep 10
    done
    %{ endif }
    curl -fsSL https://raw.githubusercontent.com/rancher/rke2/master/install.sh --output install.sh
    chmod u+x install.sh
    while true; do
      NODE_IP=$(curl -s http://169.254.169.254/hetzner/v1/metadata/private-networks | grep "ip:" | cut -f 3 -d" ")
      
      if [[ -n $NODE_IP ]]; then
        break
      fi

      echo "Empty private Node IP. Retrying..."
      sleep 1
    done
    echo "node-ip: $NODE_IP" >> /etc/rancher/rke2/config.yaml
    INSTALL_RKE2_METHOD='tar' INSTALL_RKE2_TYPE=server INSTALL_RKE2_VERSION=${rke2_version} ./install.sh
    systemctl enable rke2-server
    systemctl start rke2-server
- path: /var/lib/rancher/rke2/agent/etc/containerd/config.toml.tmpl
  permissions: "0644"
  owner: root:root
  content: |
    {{- /* */ -}}
    # File generated by {{ .Program }}. DO NOT EDIT. Use config.toml.tmpl instead.
    version = 2

    [plugins."io.containerd.internal.v1.opt"]
      path = "{{ .NodeConfig.Containerd.Opt }}"
    [plugins."io.containerd.grpc.v1.cri"]
      stream_server_address = "127.0.0.1"
      stream_server_port = "10010"
      enable_selinux = {{ .NodeConfig.SELinux }}
      enable_unprivileged_ports = {{ .EnableUnprivileged }}
      enable_unprivileged_icmp = {{ .EnableUnprivileged }}
      device_ownership_from_security_context = true

    {{- if .DisableCgroup}}
      disable_cgroup = true
    {{end}}
    {{- if .IsRunningInUserNS }}
      disable_apparmor = true
      restrict_oom_score_adj = true
    {{end}}

    {{- if .NodeConfig.AgentConfig.PauseImage }}
      sandbox_image = "{{ .NodeConfig.AgentConfig.PauseImage }}"
    {{end}}

    {{- if .NodeConfig.AgentConfig.Snapshotter }}
    [plugins."io.containerd.grpc.v1.cri".containerd]
      snapshotter = "{{ .NodeConfig.AgentConfig.Snapshotter }}"
      disable_snapshot_annotations = {{ if eq .NodeConfig.AgentConfig.Snapshotter "stargz" }}false{{else}}true{{end}}
      {{ if .NodeConfig.DefaultRuntime }}default_runtime_name = "{{ .NodeConfig.DefaultRuntime }}"{{end}}
    {{ if eq .NodeConfig.AgentConfig.Snapshotter "stargz" }}
    {{ if .NodeConfig.AgentConfig.ImageServiceSocket }}
    [plugins."io.containerd.snapshotter.v1.stargz"]
    cri_keychain_image_service_path = "{{ .NodeConfig.AgentConfig.ImageServiceSocket }}"
    [plugins."io.containerd.snapshotter.v1.stargz".cri_keychain]
    enable_keychain = true
    {{end}}

    [plugins."io.containerd.snapshotter.v1.stargz".registry]
      config_path = "{{ .NodeConfig.Containerd.Registry }}"

    {{ if .PrivateRegistryConfig }}
    {{range $k, $v := .PrivateRegistryConfig.Configs }}
    {{ if $v.Auth }}
    [plugins."io.containerd.snapshotter.v1.stargz".registry.configs."{{$k}}".auth]
      {{ if $v.Auth.Username }}username = {{ printf "%q" $v.Auth.Username }}{{end}}
      {{ if $v.Auth.Password }}password = {{ printf "%q" $v.Auth.Password }}{{end}}
      {{ if $v.Auth.Auth }}auth = {{ printf "%q" $v.Auth.Auth }}{{end}}
      {{ if $v.Auth.IdentityToken }}identitytoken = {{ printf "%q" $v.Auth.IdentityToken }}{{end}}
    {{end}}
    {{end}}
    {{end}}
    {{end}}
    {{end}}

    {{- if not .NodeConfig.NoFlannel }}
    [plugins."io.containerd.grpc.v1.cri".cni]
      bin_dir = "{{ .NodeConfig.AgentConfig.CNIBinDir }}"
      conf_dir = "{{ .NodeConfig.AgentConfig.CNIConfDir }}"
    {{end}}

    {{- if or .NodeConfig.Containerd.BlockIOConfig .NodeConfig.Containerd.RDTConfig }}
    [plugins."io.containerd.service.v1.tasks-service"]
      {{ if .NodeConfig.Containerd.BlockIOConfig }}blockio_config_file = "{{ .NodeConfig.Containerd.BlockIOConfig }}"{{end}}
      {{ if .NodeConfig.Containerd.RDTConfig }}rdt_config_file = "{{ .NodeConfig.Containerd.RDTConfig }}"{{end}}
    {{end}}

    [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
      runtime_type = "io.containerd.runc.v2"

    [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
      SystemdCgroup = {{ .SystemdCgroup }}

    [plugins."io.containerd.grpc.v1.cri".registry]
      config_path = "{{ .NodeConfig.Containerd.Registry }}"

    {{ if .PrivateRegistryConfig }}
    {{range $k, $v := .PrivateRegistryConfig.Configs }}
    {{ if $v.Auth }}
    [plugins."io.containerd.grpc.v1.cri".registry.configs."{{$k}}".auth]
      {{ if $v.Auth.Username }}username = {{ printf "%q" $v.Auth.Username }}{{end}}
      {{ if $v.Auth.Password }}password = {{ printf "%q" $v.Auth.Password }}{{end}}
      {{ if $v.Auth.Auth }}auth = {{ printf "%q" $v.Auth.Auth }}{{end}}
      {{ if $v.Auth.IdentityToken }}identitytoken = {{ printf "%q" $v.Auth.IdentityToken }}{{end}}
    {{end}}
    {{end}}
    {{end}}

    {{range $k, $v := .ExtraRuntimes}}
    [plugins."io.containerd.grpc.v1.cri".containerd.runtimes."{{$k}}"]
      runtime_type = "{{$v.RuntimeType}}"
    [plugins."io.containerd.grpc.v1.cri".containerd.runtimes."{{$k}}".options]
      BinaryName = "{{$v.BinaryName}}"
      SystemdCgroup = {{ $.SystemdCgroup }}
    {{end}}